{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tutorial-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-proportion",
   "metadata": {},
   "source": [
    "The KL divergence is given by,\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    D_{KL}(q(\\mathbf{z, z'|x, x'}) \\Vert p(\\mathbf{z, z'})) &= \\mathrm{log}\\left[\\frac{\\tilde{q}_{\\phi}(z^{(i)},z'^{(i)}|x,x')}{\\tilde{p}_{\\theta}(z^{(i)},z'^{(i)})}\\right]-\\langle \\mathbf{sg}( \\mathbb{E}_q[T]),\\lambda\\rangle-\\langle \\mathbf{sg}( \\mathbb{E}_q[T']),\\lambda'\\rangle+(\\mathbb{E}_p-\\mathbb{E}_q)\\langle \\mathbf{sg}[T\\otimes T'],G\\rangle\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    T_{prior}&=[z_{prior},z^2_{prior}]\\\\\n",
    "    T'_{prior}&=[z'_{prior},z'^2_{prior}]\\\\\n",
    "    T_{posterior}&=[z_{posterior},z^2_{posterior}]\\\\\n",
    "    T'_{posterior}&=[z'_{posterior},z'^2_{posterior}]\\\\\n",
    "    \\lambda&=[\\lambda_1,\\lambda_2]\\\\\n",
    "    \\lambda'&=[\\lambda'_1,\\lambda'_2]\\\\\n",
    "    T_{prior}^2&=(z^2_{prior}+z'^2_{prior})\\\\\n",
    "    T_{posterior}^2&=(z^2_{posterior}+z'^2_{posterior})\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "We also define,\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    \\mathrm{log}p_{prior}&=-T_{posterior}^2+T_{posterior}*G+T'_{posterior}\\\\\n",
    "    \\mathrm{log}q_{posterior}&=-T_{posterior}^2+T_{posterior}*G*T'_{posterior}+\\lambda*T_{posterior}+\\lambda'*T'_{posterior}\\\\\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "The three terms of the partition function are given by:\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    part_0&=\\sum \\mathrm{log}q_{posterior}-\\mathrm{log}p_{prior}=\\langle \\lambda,T_{posterior}\\rangle +\\langle \\lambda',T'_{posterior}\\rangle\\\\\n",
    "    part_1&=-\\langle \\lambda,sgd(T_{posterior})\\rangle -\\langle  \\lambda',sgd(T'_{posterior})\\rangle\\\\\n",
    "    part_2&=(\\mathbb{E}_p-\\mathbb{E}_q)\\langle \\mathbf{sg}[T\\otimes T'],G\\rangle\\\\\n",
    "    D_{KL}(q(\\mathbf{z, z'|x, x'}) \\Vert p(\\mathbf{z, z'})) &=part_0+part_1+part_2\n",
    "    \\end{aligned}\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brilliant-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class kl_divergence():\n",
    "    def __init__(self, latent_dim1, latent_dim2, batch_size):\n",
    "        self.latent_dim1 = latent_dim1\n",
    "        self.latent_dim2 = latent_dim2\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def calc(self,G,z1,z2,z1_prior,z2_prior,mu1,log_var1,mu2,log_var2):\n",
    "        ## Creating Sufficient statistics\n",
    "        T1_prior = torch.cat((z1_prior,torch.square(z1_prior)),1)     #sufficient statistics for prior of set1\n",
    "        T2_prior = torch.cat((z2_prior,torch.square(z2_prior)),1)   #sufficient statistics for prior of set2\n",
    "        T1_post = torch.cat((z1,torch.square(z1)),1)                  #sufficient statistics for posterior of set1\n",
    "        T2_post = torch.cat((z2,torch.square(z2)),1)                  #sufficient statistics for posterior of set2\n",
    "        lambda1 = torch.cat((mu1,log_var1),1)                       #Output of encoder for set1\n",
    "        lambda2 = torch.cat((mu2,log_var2),1)                          #Output of encoder for set2        \n",
    "        T_prior_sqrd = torch.sum(torch.square(z1_prior),1) +torch.sum(torch.square(z2_prior),1) #stores z^2+z'^2\n",
    "        T_post_sqrd  = torch.sum(torch.square(z1),1) +torch.sum(torch.square(z2),1)\n",
    "\n",
    "        #Calculating KL divergence terms\n",
    "#         part_fun0 = torch.sum(torch.mul(lambda1,T1_post))+torch.sum(torch.mul(lambda2,T2_post))\n",
    "        part_fun0 = torch.mul(lambda1,T1_post)+torch.mul(lambda2,T2_post)\n",
    "        part_fun1 = -torch.sum(torch.mul(lambda1,T1_post.detach()))-torch.sum(torch.mul(lambda2,T2_post.detach())) #-lambda*Tq-lambda'Tq' \n",
    "        part_fun1 = -torch.mul(lambda1,T1_post.detach())-torch.mul(lambda2,T2_post.detach()) #-lambda*Tq-lambda'Tq' \n",
    "        T1_prior =T1_prior.unsqueeze(2)         #[128, 2]->[128, 2,1]\n",
    "        T2_prior =T2_prior.unsqueeze(1)         #[128, 2]->[128, 1,2]\n",
    "        T1_post  =T1_post.unsqueeze(1)          #[128, 2]->[128, 1,2]\n",
    "        T2_post  =T2_post.unsqueeze(2)          #[128, 2]->[128, 2,1]\n",
    "        Tprior_kron=torch.zeros(self.batch_size,2*self.latent_dim1,2*self.latent_dim2).to(device)\n",
    "        Tpost_kron=torch.zeros(self.batch_size,2*self.latent_dim1,2*self.latent_dim2).to(device)\n",
    "\n",
    "        for i in range(self.batch_size-1):\n",
    "            Tprior_kron[i,:]=torch.kron(T1_prior[i,:], T2_prior[i,:])\n",
    "            Tpost_kron[i,:]=torch.kron(T1_post[i,:], T2_post[i,:])\n",
    "#         part_fun2 = torch.sum(torch.mul(Tprior_kron.detach(),G)-torch.mul(Tpost_kron.detach(),G))\n",
    "        part_fun2 = (torch.tensordot(Tprior_kron.detach(),G)-torch.tensordot(Tpost_kron.detach(),G))\n",
    "\n",
    "#         print('sd',torch.mul(Tprior_kron.detach(),G).size())\n",
    "        return part_fun0,part_fun1,part_fun2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "found-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=torch.randn(2,2).to(device)\n",
    "# b=torch.randn(batch_size,1).to(device)\n",
    "# c=torch.randn(batch_size,1).to(device)\n",
    "# d=torch.randn(batch_size,1).to(device)\n",
    "# e=torch.randn(batch_size,1).to(device)\n",
    "# f=torch.randn(batch_size,1).to(device)\n",
    "# g=torch.randn(batch_size,1).to(device)\n",
    "# h=torch.randn(batch_size,1).to(device)\n",
    "# qw=torch.randn(batch_size,1).to(device)\n",
    "# kl_divergence.calc(b,a,c,d,e,f,g,b,h,qw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eleven-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat1 = torch.ones(3,2)\n",
    "# mat2 = torch.ones(3,2)\n",
    "#x=torch.kron(mat1, mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arranged-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indonesian-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tprior_kron=torch.zeros(5,2,2)\n",
    "# Tprior_kron[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-potato",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
