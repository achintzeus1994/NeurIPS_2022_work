{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "natural-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from scipy.stats import multivariate_normal as mv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-murray",
   "metadata": {},
   "source": [
    "Proposal distribution:\n",
    "\n",
    "p($z_1,z_2$) = exp[-($z_1-\\mu_1$)$(\\Sigma)^2$($z_1-\\mu_1$)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "substantial-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class importance_sampler():\n",
    "    def __init__(self, latent_dim1, latent_dim2, batch_size):\n",
    "        self.latent_dim1 = latent_dim1\n",
    "        self.latent_dim2 = latent_dim2\n",
    "        self.batch_size  = batch_size\n",
    "    def sample_proposal(self,mean1,mean2,var1,var2, n_IW_samples, device=_device):\n",
    "        var1_prop = torch.diag_embed(var1) \n",
    "        var2_prop = torch.diag_embed(var2) \n",
    "        mn1 = torch.distributions.MultivariateNormal(mean1, var1_prop )\n",
    "        mn2 = torch.distributions.MultivariateNormal(mean2, var2_prop )\n",
    "        return [mn1.sample([n_IW_samples,]).to(device), mn2.sample([n_IW_samples,]).to(device)]\n",
    "\n",
    "    def proposal_dist(self,mean1,mean2,var1,var2,z1,z2, device=_device):\n",
    "        var1_diag = torch.diag_embed(var1).to(device)\n",
    "        var2_diag = torch.diag_embed(var2).to(device)\n",
    "        dist1 = torch.distributions.MultivariateNormal(mean1, var1_diag)\n",
    "        dist2 = torch.distributions.MultivariateNormal(mean2, var2_diag)\n",
    "        z_sqd = dist1.log_prob(z1)+dist2.log_prob(z2)\n",
    "#         z1_diff  = z1 - mean1\n",
    "#         z1_diff  = torch.transpose(z1_diff,0,1)\n",
    "#         z2_diff  = z2 - mean2\n",
    "#         z2_diff  = torch.transpose(z2_diff,0,1)\n",
    "#         z1_sqrd  = ((z1_diff**2)@var1_inv*(z1_diff**2)).sum(-1)\n",
    "#         z2_sqrd  = ((z2_diff**2)@var2_inv*(z2_diff**2)).sum(-1)\n",
    "#         z_sqd    = z1_sqrd+z2_sqrd\n",
    "#         var_cat = 0.5/torch.cat((var1,var2),1).to(device)   ##precision 1/(2var)\n",
    "#         var_inv = torch.diag_embed(var_cat)\n",
    "#         z_tot = torch.cat((z1,z2),2)\n",
    "#         mean_tot = torch.cat((mean1,mean2),1)\n",
    "#         z_diff = z_tot-mean_tot\n",
    "#         z_diff = torch.transpose(z_diff,0,1)\n",
    "#         z_sqd = (((z_diff)**2)@var_inv*((z_diff)**2)).sum(-1)\n",
    "#         z_sqd = -((z1-mean1)**2).sum(-1)-((z2-mean2)**2).sum(-1)               #[n_IW_samples, batch_size]\n",
    "        log_p_x = -z_sqd     \n",
    "        return log_p_x\n",
    "    def target_dist(self,G,z1,z2,mu1,var1,mu2,var2):\n",
    "        # mu1: [batch_size,latent_dim1], z1: [n_IW_samples,batch_size,latent_dim1]\n",
    "        g11 = G[:self.latent_dim1,:self.latent_dim2] #[latent_dim1, latent_dim2]\n",
    "        g12 = G[:self.latent_dim1,self.latent_dim2:] #[latent_dim1, latent_dim2]\n",
    "        g21 = G[self.latent_dim1:,:self.latent_dim2] #[latent_dim1, latent_dim2]\n",
    "        g22 = G[self.latent_dim1:,self.latent_dim2:] #[latent_dim1, latent_dim2] \n",
    "#         z_sqd = -(z1**2).sum(-1)-(z2**2).sum(-1)               #[n_IW_samples,batch_size] \n",
    "        h1   = (z1@g11*z2).sum(-1) \n",
    "        h2   = (z1@g12*(z2**2)).sum(-1) \n",
    "        h3   = ((z1**2)@g21*z2).sum(-1) \n",
    "        h4   = ((z1**2)@g22*(z2**2)).sum(-1)                  #[n_IW_samples, batch_size,latent_dim]\n",
    "        h    = (h1+h2+h3+h4)                 #[n_IW_samples, batch_size]\n",
    "        d1   = (mu1*z1+var1*(z1**2)).sum(-1) \n",
    "        d2   = (mu2*z2+var2*(z2**2)).sum(-1)                  #[n_IW_samples, batch_size,latent_dim2]\n",
    "        d    = (d1 + d2)                     #[n_IW_samples, batch_size]\n",
    "#         log_t_x    = (z_sqd+h+d)                     #[n_IW_samples, batch_size]\n",
    "        log_t_x    = h+d                     #[n_IW_samples, batch_size]\n",
    "\n",
    "        return log_t_x\n",
    "    def calc(self,G,mu1,var1,mu2,var2,n_IW_samples,mu3,var3,mu4,var4): \n",
    "        z1_posterior,z2_posterior = self.sample_proposal(mu3,mu4,var3,var4,n_IW_samples)  #[n_IW_samples,batch_size,latent_dim1],[n_IW_samples,batch_size,latent_dim2]\n",
    "#         p_x_post   = self.proposal_dist(mu3,mu4,var3,var4,z1_posterior,z2_posterior)      #[batch_size,n_IW_samples]\n",
    "#         t_x_post   = self.target_dist(G,z1_posterior, z2_posterior,mu1,var1,mu2,var2)\n",
    "#         IS_weights_post  = t_x_post   -  p_x_post\n",
    "        \n",
    "#         p_x_post   = self.proposal_dist(mu3,mu4,var3,var4,z1_posterior,z2_posterior)      #[batch_size,n_IW_samples]\n",
    "        t_x_post   = self.target_dist(G,z1_posterior, z2_posterior,mu1,var1,mu2,var2)\n",
    "        IS_weights_post  = t_x_post   \n",
    "        \n",
    "        posterior_normalization = torch.logsumexp(IS_weights_post,0)\n",
    "        diff_post = IS_weights_post - posterior_normalization\n",
    "        IS_weights_post  = torch.exp(diff_post)\n",
    "\n",
    "        return z1_posterior,z2_posterior, IS_weights_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surface-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x= torch.zeros(5)\n",
    "# y = torch.ones(5,)\n",
    "# (x*y).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frank-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_proposal(mean1,mean2,var1,var2, n_IW_samples, device=_device):\n",
    "#     var1_prop = torch.diag_embed(var1) \n",
    "#     var2_prop = torch.diag_embed(var2) \n",
    "#     mn1 = torch.distributions.MultivariateNormal(mean1, var1_prop )\n",
    "#     mn2 = torch.distributions.MultivariateNormal(mean2, var2_prop )\n",
    "#     return [mn1.sample([n_IW_samples,]).to(device), mn2.sample([n_IW_samples,]).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "curious-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean1 = torch.zeros(128,2)\n",
    "# mean2 = torch.zeros(128,2)\n",
    "# var1  = torch.ones(128,2)\n",
    "# var2  = torch.ones(128,2)\n",
    "# n_IW_samples = 5\n",
    "# z1,z2 =sample_proposal(mean1,mean2,var1,var2,n_IW_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "possible-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "descending-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z1_numpy = z1.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "played-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z11 = np.reshape(z1_numpy,(3000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hired-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# n, bins, patches = plt.hist(z11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "annual-crazy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from torch.distributions import MultivariateNormal \n",
    "\n",
    "# means = torch.tensor([0.0538,\n",
    "#         0.0651])\n",
    "# stds = torch.tensor([[0.7865,0],\n",
    "#         [0,0.7792]])\n",
    "\n",
    "# dist = MultivariateNormal(means, stds)\n",
    "# a = torch.tensor([1.2,3.4])\n",
    "# d = dist.log_prob(a)\n",
    "# print(d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "based-producer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 128])\n"
     ]
    }
   ],
   "source": [
    "# z1 = torch.randn(10,128,1)\n",
    "# mean = torch.zeros(128,1)\n",
    "# stds = torch.ones(128,1)\n",
    "# stds_diag = torch.diag_embed(stds)\n",
    "# dist = MultivariateNormal(mean, stds_diag)\n",
    "# d = dist.log_prob(z1)\n",
    "# print(d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-oakland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
